{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda40e2f-a1b3-4eb9-b2f5-3e4feb275426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from math import log2\n",
    "\n",
    "w1 = 0.7\n",
    "w2 = 0.3\n",
    "N_COLD = 15\n",
    "SPLIT_Q = 0.8\n",
    "train_path = \"./data/raw/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66c75fa-0860-44a2-8df3-ce595e29f781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id               int64\n",
      "book_id               int64\n",
      "has_read              int64\n",
      "rating                int64\n",
      "timestamp    datetime64[ns]\n",
      "dtype: object\n",
      "   user_id  book_id  has_read  rating           timestamp\n",
      "0     3870   310170         0       0 2008-04-27 21:06:16\n",
      "1     3870   306406         0       0 2008-06-07 11:51:01\n",
      "2     4091   195676         0       0 2008-08-06 00:40:55\n",
      "3     3870   554261         1       8 2008-08-07 09:16:12\n",
      "4     3870    33078         1       2 2008-08-07 09:17:20\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "\n",
    "print(train.dtypes.head())\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0923b8e4-0d4f-4e3f-8c77-78988416995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_split (80-й перцентиль): 2020-09-11 23:28:35\n",
      "Размер train_hist: (215249, 5)\n",
      "Размер val_period: (53812, 5)\n",
      "\n",
      "train_hist диапазон времени: 2008-04-27 21:06:16 → 2020-09-11 23:28:35\n",
      "val_period диапазон времени: 2020-09-11 23:30:30 → 2021-09-06 00:17:11\n"
     ]
    }
   ],
   "source": [
    "split_point = train['timestamp'].quantile(SPLIT_Q)\n",
    "print(\"T_split (80-й перцентиль):\", split_point)\n",
    "\n",
    "train_hist = train[train['timestamp'] <= split_point].copy()\n",
    "val_period = train[train['timestamp'] > split_point].copy()\n",
    "\n",
    "print(\"Размер train_hist:\", train_hist.shape)\n",
    "print(\"Размер val_period:\", val_period.shape)\n",
    "\n",
    "print(\"\\ntrain_hist диапазон времени:\",\n",
    "      train_hist['timestamp'].min(), \"→\", train_hist['timestamp'].max())\n",
    "print(\"val_period диапазон времени:\",\n",
    "      val_period['timestamp'].min(), \"→\", val_period['timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93db8a9-a190-4029-8bcc-f148fadb0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_history_and_popularity(df):\n",
    "    user_hist_books = (\n",
    "        df\n",
    "        .groupby('user_id')['book_id']\n",
    "        .agg(lambda x: set(x.tolist()))\n",
    "        .to_dict()\n",
    "    )\n",
    "    book_popularity = (\n",
    "        df\n",
    "        .groupby('book_id')['user_id']\n",
    "        .nunique()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    popular_books = book_popularity.index.to_numpy()\n",
    "    return user_hist_books, popular_books\n",
    "\n",
    "\n",
    "def sample_cold_candidates_for_user(user_id, user_hist_books, popular_books, n_cold=N_COLD):\n",
    "    seen = user_hist_books.get(user_id, set())\n",
    "    cold = []\n",
    "    for b in popular_books:\n",
    "        if b not in seen:\n",
    "            cold.append(b)\n",
    "            if len(cold) >= n_cold:\n",
    "                break\n",
    "    return cold\n",
    "\n",
    "\n",
    "def build_cold_candidates(users, user_hist_books, popular_books, n_cold=N_COLD):\n",
    "    rows = []\n",
    "    for u in users:\n",
    "        cold_books = sample_cold_candidates_for_user(u, user_hist_books, popular_books, n_cold=n_cold)\n",
    "        for b in cold_books:\n",
    "            rows.append((u, b, 0))\n",
    "    df = pd.DataFrame(rows, columns=['user_id', 'book_id', 'rel'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_basic_features(df_candidates, user_stats_df, book_stats_df):\n",
    "    df = df_candidates.copy()\n",
    "    df = df.merge(user_stats_df, on='user_id', how='left')\n",
    "    df = df.merge(book_stats_df, on='book_id', how='left')\n",
    "    df = df.fillna(0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c60b885-0745-405b-9168-09f3861c0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(rels, k=20):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    if rels.size == 0:\n",
    "        return 0.0\n",
    "    return float(sum(rel / log2(i + 2) for i, rel in enumerate(rels)))\n",
    "\n",
    "\n",
    "def ndcg_for_user(df_u, k=20):\n",
    "    df_sorted = df_u.sort_values('pred', ascending=False)\n",
    "    rels_pred = df_sorted['rel'].values\n",
    "    dcg = dcg_at_k(rels_pred, k=k)\n",
    "    ideal_rels = np.sort(df_u['rel'].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_rels, k=k)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "def mean_ndcg(df, k=20):\n",
    "    scores = []\n",
    "    for user_id, df_u in df.groupby('user_id'):\n",
    "        score_u = ndcg_for_user(df_u, k=k)\n",
    "        scores.append(score_u)\n",
    "    if not scores:\n",
    "        return 0.0\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "def make_submission_user_list(df_pred, top_k=20):\n",
    "    submission_rows = []\n",
    "    for user_id, df_u in df_pred.groupby('user_id'):\n",
    "        df_sorted = df_u.sort_values('pred', ascending=False)\n",
    "        top_books = df_sorted['book_id'].head(top_k).tolist()\n",
    "        book_id_list_str = \",\".join(map(str, top_books))\n",
    "        submission_rows.append((user_id, book_id_list_str))\n",
    "    sub = pd.DataFrame(submission_rows, columns=['user_id', 'book_id_list'])\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ced047e2-3577-43b0-9d16-1f4ed96c2081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позитивные/полупозитивные примеры в val_period: (53812, 3)\n",
      "        user_id  book_id  rel\n",
      "215249  1551451  2573361    2\n",
      "215250  1397150  2538344    2\n",
      "215251  1358090  2019613    2\n",
      "215252   849910  2366271    2\n",
      "215253   849910  1716389    1\n",
      "Количество холодных кандидатов: (60495, 3)\n",
      "   user_id  book_id  rel\n",
      "0  1551451   459282    0\n",
      "1  1551451  2287749    0\n",
      "2  1551451  2318816    0\n",
      "3  1551451  1796985    0\n",
      "4  1551451  1360858    0\n",
      "Итоговый размер val_candidates: (113171, 3)\n",
      "   user_id  book_id  rel\n",
      "0  1551451  2573361    2\n",
      "1  1397150  2538344    2\n",
      "2  1358090  2019613    2\n",
      "3   849910  2366271    2\n",
      "4   849910  1716389    1\n"
     ]
    }
   ],
   "source": [
    "val_period = val_period.copy()\n",
    "val_period['rel'] = np.where(val_period['has_read'] == 1, 2, 1)\n",
    "val_pos = val_period[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "print(\"Позитивные/полупозитивные примеры в val_period:\", val_pos.shape)\n",
    "print(val_pos.head())\n",
    "\n",
    "user_hist_books_hist, popular_books_hist = build_history_and_popularity(train_hist)\n",
    "val_users = val_period['user_id'].unique()\n",
    "val_cold = build_cold_candidates(val_users, user_hist_books_hist, popular_books_hist, n_cold=N_COLD)\n",
    "\n",
    "print(\"Количество холодных кандидатов:\", val_cold.shape)\n",
    "print(val_cold.head())\n",
    "\n",
    "val_candidates = pd.concat([val_pos, val_cold], ignore_index=True)\n",
    "val_candidates = val_candidates.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Итоговый размер val_candidates:\", val_candidates.shape)\n",
    "print(val_candidates.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9971a5f-3c66-4141-9bad-362cceeaf11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train_candidates_hist: (305519, 3)\n",
      "Распределение rel в train_candidates_hist:\n",
      "rel\n",
      "0     90270\n",
      "1     89214\n",
      "2    126035\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_hist_full = train_hist.copy()\n",
    "train_hist_full['rel'] = np.where(train_hist_full['has_read'] == 1, 2, 1)\n",
    "train_hist_pos = train_hist_full[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "train_hist_users = train_hist_full['user_id'].unique()\n",
    "train_hist_cold = build_cold_candidates(train_hist_users, user_hist_books_hist, popular_books_hist, n_cold=N_COLD)\n",
    "\n",
    "train_candidates_hist = pd.concat([train_hist_pos, train_hist_cold], ignore_index=True)\n",
    "train_candidates_hist = train_candidates_hist.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Размер train_candidates_hist:\", train_candidates_hist.shape)\n",
    "print(\"Распределение rel в train_candidates_hist:\")\n",
    "print(train_candidates_hist['rel'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894ea982-ccab-47de-aeac-1e898e29444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример агрегатов по книгам (hist):\n",
      "   book_id  n_interactions  n_read  n_plan  read_rate  plan_rate\n",
      "0       20             111      94      17   0.846847   0.153153\n",
      "1       35               1       1       0   0.999999   0.000000\n",
      "2       52               1       1       0   0.999999   0.000000\n",
      "3       54               5       4       1   0.800000   0.200000\n",
      "4       69               1       1       0   0.999999   0.000000\n",
      "Пример агрегатов по пользователям (hist):\n",
      "   user_id  u_n_interactions  u_n_read  u_n_plan  u_read_share\n",
      "0      151                75        36        39      0.480000\n",
      "1      210                31         0        31      0.000000\n",
      "2      560                 5         0         5      0.000000\n",
      "3     1380                46        19        27      0.413043\n",
      "4     1850                77        38        39      0.493506\n"
     ]
    }
   ],
   "source": [
    "book_stats_hist = (train_hist\n",
    "    .groupby('book_id')\n",
    "    .agg(\n",
    "        n_interactions=('user_id', 'nunique'),\n",
    "        n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "book_stats_hist['read_rate'] = book_stats_hist['n_read'] / (book_stats_hist['n_read'] + book_stats_hist['n_plan'] + 1e-6)\n",
    "book_stats_hist['plan_rate'] = book_stats_hist['n_plan'] / (book_stats_hist['n_read'] + book_stats_hist['n_plan'] + 1e-6)\n",
    "\n",
    "user_stats_hist = (train_hist\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        u_n_interactions=('book_id', 'nunique'),\n",
    "        u_n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        u_n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_stats_hist['u_read_share'] = user_stats_hist['u_n_read'] / (user_stats_hist['u_n_interactions'] + 1e-6)\n",
    "\n",
    "print(\"Пример агрегатов по книгам (hist):\")\n",
    "print(book_stats_hist.head())\n",
    "print(\"Пример агрегатов по пользователям (hist):\")\n",
    "print(user_stats_hist.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faabdbae-6b5b-44a3-bae0-ae765da8f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков: 9\n",
      "Распределение rel в train_features_hist:\n",
      "rel\n",
      "0     90270\n",
      "1     89214\n",
      "2    126035\n",
      "Name: count, dtype: int64\n",
      "Распределение rel в val_features:\n",
      "rel\n",
      "0    59359\n",
      "1    23244\n",
      "2    30568\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_features_hist = add_basic_features(train_candidates_hist, user_stats_hist, book_stats_hist)\n",
    "val_features = add_basic_features(val_candidates, user_stats_hist, book_stats_hist)\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in train_features_hist.columns\n",
    "    if c not in ['user_id', 'book_id', 'rel']\n",
    "]\n",
    "\n",
    "X_train = train_features_hist[feature_cols]\n",
    "y_train_rel = train_features_hist['rel']\n",
    "y_train_read = (train_features_hist['rel'] == 2).astype(int)\n",
    "y_train_any = (train_features_hist['rel'] > 0).astype(int)\n",
    "\n",
    "X_val = val_features[feature_cols]\n",
    "y_val_rel = val_features['rel']\n",
    "\n",
    "print(\"Число признаков:\", len(feature_cols))\n",
    "print(\"Распределение rel в train_features_hist:\")\n",
    "print(y_train_rel.value_counts().sort_index())\n",
    "print(\"Распределение rel в val_features:\")\n",
    "print(y_val_rel.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054804e0-229b-4c98-8784-9d36a8580201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример предсказаний (валидация):\n",
      "   user_id  book_id  rel      pred\n",
      "0  1551451  2573361    2  0.999882\n",
      "1  1397150  2538344    2  0.802537\n",
      "2  1358090  2019613    2  0.998972\n",
      "3   849910  2366271    2  0.776388\n",
      "4   849910  1716389    1  0.776298\n"
     ]
    }
   ],
   "source": [
    "xgb_read_cv = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_any_cv = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=43,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_read_cv.fit(X_train, y_train_read)\n",
    "xgb_any_cv.fit(X_train, y_train_any)\n",
    "\n",
    "cb_read_cv = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "cb_any_cv = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=43\n",
    ")\n",
    "\n",
    "cb_read_cv.fit(X_train, y_train_read)\n",
    "cb_any_cv.fit(X_train, y_train_any)\n",
    "\n",
    "p_read_xgb_val = xgb_read_cv.predict_proba(X_val)[:, 1]\n",
    "p_any_xgb_val = xgb_any_cv.predict_proba(X_val)[:, 1]\n",
    "score_xgb_val = w1 * p_read_xgb_val + w2 * p_any_xgb_val\n",
    "\n",
    "p_read_cb_val = cb_read_cv.predict_proba(X_val)[:, 1]\n",
    "p_any_cb_val = cb_any_cv.predict_proba(X_val)[:, 1]\n",
    "score_cb_val = w1 * p_read_cb_val + w2 * p_any_cb_val\n",
    "\n",
    "val_features['score_xgb'] = score_xgb_val\n",
    "val_features['score_cb'] = score_cb_val\n",
    "val_features['score_ens'] = (score_xgb_val + score_cb_val) / 2.0\n",
    "val_features['pred'] = val_features['score_ens']\n",
    "\n",
    "print(\"Пример предсказаний (валидация):\")\n",
    "print(val_features[['user_id', 'book_id', 'rel', 'pred']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2461021-65a4-4606-b252-85200c08cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@20 на валидации: 0.95756\n"
     ]
    }
   ],
   "source": [
    "ndcg20 = mean_ndcg(val_features, k=20)\n",
    "print(f\"NDCG@20 на валидации: {ndcg20:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a934433-c323-4f7a-a481-44f226dcebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train_candidates_full: (378396, 3)\n",
      "Распределение rel в train_candidates_full:\n",
      "rel\n",
      "0    109335\n",
      "1    112458\n",
      "2    156603\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_full = train.copy()\n",
    "train_full['rel'] = np.where(train_full['has_read'] == 1, 2, 1)\n",
    "train_pos_full = train_full[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "user_hist_books_full, popular_books_full = build_history_and_popularity(train)\n",
    "train_users_full = train_full['user_id'].unique()\n",
    "train_cold_full = build_cold_candidates(train_users_full, user_hist_books_full, popular_books_full, n_cold=N_COLD)\n",
    "\n",
    "train_candidates_full = pd.concat([train_pos_full, train_cold_full], ignore_index=True)\n",
    "train_candidates_full = train_candidates_full.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Размер train_candidates_full:\", train_candidates_full.shape)\n",
    "print(\"Распределение rel в train_candidates_full:\")\n",
    "print(train_candidates_full['rel'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f95d79d-93c0-4f97-8be2-39ff926c4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример агрегатов по книгам (full):\n",
      "   book_id  n_interactions  n_read  n_plan  read_rate  plan_rate\n",
      "0       20             122     103      19   0.844262   0.155738\n",
      "1       35               1       1       0   0.999999   0.000000\n",
      "2       52               1       1       0   0.999999   0.000000\n",
      "3       54               7       5       2   0.714286   0.285714\n",
      "4       69               1       1       0   0.999999   0.000000\n",
      "Пример агрегатов по пользователям (full):\n",
      "   user_id  u_n_interactions  u_n_read  u_n_plan  u_read_share\n",
      "0      151                75        36        39      0.480000\n",
      "1      210                31         0        31      0.000000\n",
      "2      560                 6         0         6      0.000000\n",
      "3     1380                56        29        27      0.517857\n",
      "4     1850                77        38        39      0.493506\n"
     ]
    }
   ],
   "source": [
    "book_stats_full = (train\n",
    "    .groupby('book_id')\n",
    "    .agg(\n",
    "        n_interactions=('user_id', 'nunique'),\n",
    "        n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "book_stats_full['read_rate'] = book_stats_full['n_read'] / (book_stats_full['n_read'] + book_stats_full['n_plan'] + 1e-6)\n",
    "book_stats_full['plan_rate'] = book_stats_full['n_plan'] / (book_stats_full['n_read'] + book_stats_full['n_plan'] + 1e-6)\n",
    "\n",
    "user_stats_full = (train\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        u_n_interactions=('book_id', 'nunique'),\n",
    "        u_n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        u_n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_stats_full['u_read_share'] = user_stats_full['u_n_read'] / (user_stats_full['u_n_interactions'] + 1e-6)\n",
    "\n",
    "print(\"Пример агрегатов по книгам (full):\")\n",
    "print(book_stats_full.head())\n",
    "print(\"Пример агрегатов по пользователям (full):\")\n",
    "print(user_stats_full.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5980108-1fe6-4d3d-a54b-6b15a0e020bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков (full): 9\n",
      "Распределение rel (full):\n",
      "rel\n",
      "0    109335\n",
      "1    112458\n",
      "2    156603\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_features_full = add_basic_features(train_candidates_full, user_stats_full, book_stats_full)\n",
    "\n",
    "feature_cols_full = [\n",
    "    c for c in train_features_full.columns\n",
    "    if c not in ['user_id', 'book_id', 'rel']\n",
    "]\n",
    "\n",
    "X_full = train_features_full[feature_cols_full]\n",
    "y_full_rel = train_features_full['rel']\n",
    "y_full_read = (train_features_full['rel'] == 2).astype(int)\n",
    "y_full_any = (train_features_full['rel'] > 0).astype(int)\n",
    "\n",
    "print(\"Число признаков (full):\", len(feature_cols_full))\n",
    "print(\"Распределение rel (full):\")\n",
    "print(y_full_rel.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373c9537-1908-4724-841b-bf551e2b2832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальные модели (XGBoost + CatBoost) обучены на полном тренировочном датасете.\n"
     ]
    }
   ],
   "source": [
    "xgb_read_full = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_any_full = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=101,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_read_full.fit(X_full, y_full_read)\n",
    "xgb_any_full.fit(X_full, y_full_any)\n",
    "\n",
    "cb_read_full = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=100\n",
    ")\n",
    "\n",
    "cb_any_full = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=101\n",
    ")\n",
    "\n",
    "cb_read_full.fit(X_full, y_full_read)\n",
    "cb_any_full.fit(X_full, y_full_any)\n",
    "\n",
    "print(\"Финальные модели (XGBoost + CatBoost) обучены на полном тренировочном датасете.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e09f03bc-42e8-422b-b4fd-89480c12abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер candidates_raw: (3512, 2)\n",
      "Колонки candidates_raw: ['user_id', 'book_id_list']\n",
      "   user_id                                       book_id_list\n",
      "0      210  11936,254097,709075,840500,971259,1037723,1074...\n",
      "1     1380  8369,28302,145975,482934,625734,998313,1098150...\n",
      "2     2050  4902,8369,18790,308364,317849,460492,822326,86...\n",
      "3     2740  39221,112023,149611,162418,181062,317050,43565...\n",
      "4     4621  28638,28639,28642,28901,31479,307058,475353,57...\n",
      "Длинный формат candidates_long: (81048, 2)\n",
      "   user_id  book_id\n",
      "0      210    11936\n",
      "0      210   254097\n",
      "0      210   709075\n",
      "0      210   840500\n",
      "0      210   971259\n"
     ]
    }
   ],
   "source": [
    "candidates_path = \"./data/raw/candidates.csv\"\n",
    "candidates_raw = pd.read_csv(candidates_path)\n",
    "\n",
    "print(\"Размер candidates_raw:\", candidates_raw.shape)\n",
    "print(\"Колонки candidates_raw:\", candidates_raw.columns.tolist())\n",
    "print(candidates_raw.head())\n",
    "\n",
    "candidates_long = candidates_raw.copy()\n",
    "candidates_long['book_id_list'] = candidates_long['book_id_list'].fillna('').astype(str)\n",
    "candidates_long['book_id_list'] = candidates_long['book_id_list'].str.split(',')\n",
    "candidates_long = candidates_long.explode('book_id_list')\n",
    "candidates_long = candidates_long[candidates_long['book_id_list'].str.strip() != '']\n",
    "candidates_long['book_id'] = candidates_long['book_id_list'].str.strip().astype(int)\n",
    "candidates_long = candidates_long[['user_id', 'book_id']].drop_duplicates()\n",
    "\n",
    "print(\"Длинный формат candidates_long:\", candidates_long.shape)\n",
    "print(candidates_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2c06457-1a57-40d3-b6bb-f36f733c8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер test_features после join'ов: (81048, 11)\n",
      "   user_id  book_id  u_n_interactions  u_n_read  u_n_plan  u_read_share  \\\n",
      "0      210    11936                31         0        31           0.0   \n",
      "1      210   254097                31         0        31           0.0   \n",
      "2      210   709075                31         0        31           0.0   \n",
      "3      210   840500                31         0        31           0.0   \n",
      "4      210   971259                31         0        31           0.0   \n",
      "\n",
      "   n_interactions  n_read  n_plan  read_rate  plan_rate  \n",
      "0           396.0   375.0    21.0   0.946970   0.053030  \n",
      "1           360.0   325.0    35.0   0.902778   0.097222  \n",
      "2           198.0   130.0    68.0   0.656566   0.343434  \n",
      "3            91.0    70.0    21.0   0.769231   0.230769  \n",
      "4             1.0     0.0     1.0   0.000000   0.999999  \n",
      "Пример предсказаний на candidates_long:\n",
      "   user_id  book_id      pred\n",
      "0      210    11936  0.240431\n",
      "1      210   254097  0.306785\n",
      "2      210   709075  0.300821\n",
      "3      210   840500  0.301159\n",
      "4      210   971259  0.300013\n"
     ]
    }
   ],
   "source": [
    "test_features = add_basic_features(candidates_long, user_stats_full, book_stats_full)\n",
    "\n",
    "print(\"Размер test_features после join'ов:\", test_features.shape)\n",
    "print(test_features.head())\n",
    "\n",
    "X_test = test_features[feature_cols_full]\n",
    "\n",
    "p_read_xgb_test = xgb_read_full.predict_proba(X_test)[:, 1]\n",
    "p_any_xgb_test = xgb_any_full.predict_proba(X_test)[:, 1]\n",
    "score_xgb_test = w1 * p_read_xgb_test + w2 * p_any_xgb_test\n",
    "\n",
    "p_read_cb_test = cb_read_full.predict_proba(X_test)[:, 1]\n",
    "p_any_cb_test = cb_any_full.predict_proba(X_test)[:, 1]\n",
    "score_cb_test = w1 * p_read_cb_test + w2 * p_any_cb_test\n",
    "\n",
    "test_features['score_xgb'] = score_xgb_test\n",
    "test_features['score_cb'] = score_cb_test\n",
    "test_features['pred'] = (score_xgb_test + score_cb_test) / 2.0\n",
    "\n",
    "print(\"Пример предсказаний на candidates_long:\")\n",
    "print(test_features[['user_id', 'book_id', 'pred']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83c1b0f2-3acb-4812-b783-c94b2bf47f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример сабмита (формат A):\n",
      "   user_id                                       book_id_list\n",
      "0      210  2370751,254097,2286120,2180196,840500,2300795,...\n",
      "1     1380  2290484,2548861,482934,2379664,8467358,28302,8...\n",
      "2     2050  1021078,460492,1918727,2575827,867246,18790,23...\n",
      "3     2740  987516,112023,2327258,1834192,5535190,2479424,...\n",
      "4     4621  1809950,2595660,2446687,1964216,2347566,134176...\n",
      "Сабмит сохранён в: ./output/submissions/submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_user_list = make_submission_user_list(test_features, top_k=20)\n",
    "\n",
    "print(\"Пример сабмита (формат A):\")\n",
    "print(submission_user_list.head())\n",
    "\n",
    "submit_path = \"./output/submissions/submission.csv\"\n",
    "submission_user_list.to_csv(submit_path, index=False)\n",
    "print(\"Сабмит сохранён в:\", submit_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
