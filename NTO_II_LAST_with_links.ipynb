{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bda40e2f-a1b3-4eb9-b2f5-3e4feb275426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from math import log2\n",
    "\n",
    "w1 = 0.7\n",
    "w2 = 0.3\n",
    "N_COLD = 15\n",
    "SPLIT_Q = 0.8\n",
    "train_path = \"./data/raw/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a66c75fa-0860-44a2-8df3-ce595e29f781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id               int64\n",
      "book_id               int64\n",
      "has_read              int64\n",
      "rating                int64\n",
      "timestamp    datetime64[ns]\n",
      "dtype: object\n",
      "   user_id  book_id  has_read  rating           timestamp\n",
      "0     3870   310170         0       0 2008-04-27 21:06:16\n",
      "1     3870   306406         0       0 2008-06-07 11:51:01\n",
      "2     4091   195676         0       0 2008-08-06 00:40:55\n",
      "3     3870   554261         1       8 2008-08-07 09:16:12\n",
      "4     3870    33078         1       2 2008-08-07 09:17:20\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "\n",
    "print(train.dtypes.head())\n",
    "print(train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b418aac-3ff8-4047-8874-5b1fab1f49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_metadata_df = pd.read_csv(\"./data/raw/books.csv\")\n",
    "book_genres_df = pd.read_csv(\"./data/./raw/book_genres.csv\")\n",
    "\n",
    "# Группируем жанры в список для каждой книги\n",
    "genre_lists = book_genres_df.groupby('book_id')['genre_id'].apply(list).reset_index()\n",
    "books_metadata_df = books_metadata_df.merge(genre_lists, on='book_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bf143cac-3bfc-451a-a363-bf29a803ac33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>language</th>\n",
       "      <th>publisher</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Вероника решает умереть</td>\n",
       "      <td>21</td>\n",
       "      <td>Пауло Коэльо</td>\n",
       "      <td>2019</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>4.95082</td>\n",
       "      <td>[433, 1217]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>Самое жуткое приключение</td>\n",
       "      <td>33</td>\n",
       "      <td>Р. Л. Стайн</td>\n",
       "      <td>2002</td>\n",
       "      <td>119</td>\n",
       "      <td>122</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>[141, 142, 146, 1223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>Разводящий Апокалипсиса</td>\n",
       "      <td>50</td>\n",
       "      <td>Сергей Щеглов</td>\n",
       "      <td>2001</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>[1251, 1314]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Вердикт</td>\n",
       "      <td>14088</td>\n",
       "      <td>Джон Гришэм</td>\n",
       "      <td>2021</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>[125, 127, 433]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>Как выжить с мужчиной</td>\n",
       "      <td>69</td>\n",
       "      <td>Иоанна Хмелевская</td>\n",
       "      <td>2001</td>\n",
       "      <td>119</td>\n",
       "      <td>157</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>[127, 1280]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55780</th>\n",
       "      <td>8494181</td>\n",
       "      <td>Рассказы Люси Синицыной, ученицы третьего класса</td>\n",
       "      <td>25612</td>\n",
       "      <td>Ирина Пивоварова</td>\n",
       "      <td>2016</td>\n",
       "      <td>119</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[141]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55781</th>\n",
       "      <td>8508008</td>\n",
       "      <td>Крейцерова соната</td>\n",
       "      <td>5497</td>\n",
       "      <td>Лев Толстой</td>\n",
       "      <td>2012</td>\n",
       "      <td>119</td>\n",
       "      <td>69</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>[441, 446]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55782</th>\n",
       "      <td>8508119</td>\n",
       "      <td>Казаки</td>\n",
       "      <td>5497</td>\n",
       "      <td>Лев Толстой</td>\n",
       "      <td>2013</td>\n",
       "      <td>119</td>\n",
       "      <td>14</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>[446]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55783</th>\n",
       "      <td>8536472</td>\n",
       "      <td>Безмятежный лотос в мире демонов</td>\n",
       "      <td>2393731</td>\n",
       "      <td>Алекс Го</td>\n",
       "      <td>2025</td>\n",
       "      <td>119</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1133, 1391]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55784</th>\n",
       "      <td>8545715</td>\n",
       "      <td>Пять женщин, предавшихся любви</td>\n",
       "      <td>16222</td>\n",
       "      <td>Ихара Сайкаку</td>\n",
       "      <td>2024</td>\n",
       "      <td>119</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>[412]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55785 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       book_id                                             title  author_id  \\\n",
       "0           20                           Вероника решает умереть         21   \n",
       "1           35                          Самое жуткое приключение         33   \n",
       "2           52                           Разводящий Апокалипсиса         50   \n",
       "3           54                                           Вердикт      14088   \n",
       "4           69                             Как выжить с мужчиной         69   \n",
       "...        ...                                               ...        ...   \n",
       "55780  8494181  Рассказы Люси Синицыной, ученицы третьего класса      25612   \n",
       "55781  8508008                                 Крейцерова соната       5497   \n",
       "55782  8508119                                            Казаки       5497   \n",
       "55783  8536472                  Безмятежный лотос в мире демонов    2393731   \n",
       "55784  8545715                    Пять женщин, предавшихся любви      16222   \n",
       "\n",
       "             author_name  publication_year  language  publisher  avg_rating  \\\n",
       "0           Пауло Коэльо              2019       119          9     4.95082   \n",
       "1            Р. Л. Стайн              2002       119        122     0.00000   \n",
       "2          Сергей Щеглов              2001       119          9     6.00000   \n",
       "3            Джон Гришэм              2021       119          9     4.00000   \n",
       "4      Иоанна Хмелевская              2001       119        157     8.00000   \n",
       "...                  ...               ...       ...        ...         ...   \n",
       "55780   Ирина Пивоварова              2016       119          9         NaN   \n",
       "55781        Лев Толстой              2012       119         69     5.00000   \n",
       "55782        Лев Толстой              2013       119         14     2.00000   \n",
       "55783           Алекс Го              2025       119          7         NaN   \n",
       "55784      Ихара Сайкаку              2024       119          7     0.00000   \n",
       "\n",
       "                    genre_id  \n",
       "0                [433, 1217]  \n",
       "1      [141, 142, 146, 1223]  \n",
       "2               [1251, 1314]  \n",
       "3            [125, 127, 433]  \n",
       "4                [127, 1280]  \n",
       "...                      ...  \n",
       "55780                  [141]  \n",
       "55781             [441, 446]  \n",
       "55782                  [446]  \n",
       "55783           [1133, 1391]  \n",
       "55784                  [412]  \n",
       "\n",
       "[55785 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0923b8e4-0d4f-4e3f-8c77-78988416995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_split (80-й перцентиль): 2020-09-11 23:28:35\n",
      "Размер train_hist: (215249, 5)\n",
      "Размер val_period: (53812, 5)\n",
      "\n",
      "train_hist диапазон времени: 2008-04-27 21:06:16 → 2020-09-11 23:28:35\n",
      "val_period диапазон времени: 2020-09-11 23:30:30 → 2021-09-06 00:17:11\n"
     ]
    }
   ],
   "source": [
    "split_point = train['timestamp'].quantile(SPLIT_Q)\n",
    "print(\"T_split (80-й перцентиль):\", split_point)\n",
    "\n",
    "train_hist = train[train['timestamp'] <= split_point].copy()\n",
    "val_period = train[train['timestamp'] > split_point].copy()\n",
    "\n",
    "print(\"Размер train_hist:\", train_hist.shape)\n",
    "print(\"Размер val_period:\", val_period.shape)\n",
    "\n",
    "print(\"\\ntrain_hist диапазон времени:\",\n",
    "      train_hist['timestamp'].min(), \"→\", train_hist['timestamp'].max())\n",
    "print(\"val_period диапазон времени:\",\n",
    "      val_period['timestamp'].min(), \"→\", val_period['timestamp'].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "441e9bd0-9385-4371-ba18-8e5506761a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_interaction_features(df_candidates, train_hist_df):\n",
    "    \"\"\"\n",
    "    Добавляет признаки, связанные с историей взаимодействия пользователя с книгой.\n",
    "    \"\"\"s\n",
    "    df = df_candidates.copy()\n",
    "    \n",
    "    # Признак: было ли взаимодействие (user_id, book_id) в train_hist\n",
    "    interactions_set = set(train_hist_df.set_index(['user_id', 'book_id']).index)\n",
    "    df['has_interacted'] = df.apply(lambda row: (row['user_id'], row['book_id']) in interactions_set, axis=1).astype(int)\n",
    "    \n",
    "    # Признак: рейтинг, который пользователь поставил этой книге (если ставил)\n",
    "    user_book_rating = train_hist_df.groupby(['user_id', 'book_id'])['rating'].first().to_dict()\n",
    "    df['user_book_rating'] = df.apply(lambda row: user_book_rating.get((row['user_id'], row['book_id']), 0), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_temporal_features(df_candidates, train_hist_df, split_time=train['timestamp'].max()):\n",
    "    \"\"\"\n",
    "    Добавляет признаки, основанные на временных метках.\n",
    "    split_time: datetime - время разбиения. Используется для вычисления days_since_last_interaction.\n",
    "                Если None, используется max timestamp из train_hist_df.\n",
    "    \"\"\"\n",
    "    df = df_candidates.copy()\n",
    "\n",
    "    # Средняя дата взаимодействия с книгами, которые пользователь прочитал\n",
    "    user_read_timestamps = (\n",
    "        train_hist_df[train_hist_df['has_read'] == 1]\n",
    "        .groupby('user_id')['timestamp']\n",
    "        .agg(['mean', 'max', 'min'])\n",
    "        .add_prefix('u_read_timestamp_')\n",
    "        .reset_index()\n",
    "    )\n",
    "    df = df.merge(user_read_timestamps, on='user_id', how='left')\n",
    "\n",
    "    # Средняя дата взаимодействия с этой конкретной книгой\n",
    "    book_timestamps = (\n",
    "        train_hist_df.groupby('book_id')['timestamp']\n",
    "        .agg(['mean', 'max', 'min'])\n",
    "        .add_prefix('b_timestamp_')\n",
    "        .reset_index()\n",
    "    )\n",
    "    df = df.merge(book_timestamps, on='book_id', how='left')\n",
    "\n",
    "    # --- Исправление: Преобразуем datetime в числовой формат (дни с 1970-01-01) ---\n",
    "    # Определяем базовую дату для преобразования\n",
    "    base_date = pd.Timestamp('1970-01-01')\n",
    "\n",
    "    # Преобразуем столбцы с датами в дни\n",
    "    temporal_cols_to_convert = [\n",
    "        'u_read_timestamp_mean', 'u_read_timestamp_max', 'u_read_timestamp_min',\n",
    "        'b_timestamp_mean', 'b_timestamp_max', 'b_timestamp_min'\n",
    "    ]\n",
    "\n",
    "    for col in temporal_cols_to_convert:\n",
    "        if col in df.columns:\n",
    "            # Проверяем, является ли столбец datetime\n",
    "            if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "                # Преобразуем в дни от базовой даты\n",
    "                # .dt.total_seconds() / (24 * 3600) - это альтернатива .dt.days\n",
    "                df[col] = (df[col] - base_date).dt.days\n",
    "\n",
    "    # --- Конец исправления ---\n",
    "\n",
    "    # --- Исправление: Вычисляем days_since_last_interaction ---\n",
    "    # Определяем время \"предсказания\" для вычисления разницы\n",
    "    if split_time is None:\n",
    "        # Если split_time не задан, используем максимальное время из истории как приближение\n",
    "        prediction_time_days = (train_hist_df['timestamp'].max() - base_date).days\n",
    "    else:\n",
    "        prediction_time_days = (split_time - base_date).days\n",
    "\n",
    "    # Признак: сколько дней прошло с последнего взаимодействия с книгой\n",
    "    # (для cold candidates b_timestamp_max_days будет NaN)\n",
    "    # Вычисляем разницу между 'prediction_time_days' и 'b_timestamp_max_days'\n",
    "    # Предполагаем, что 'b_timestamp_max' уже был преобразован в дни выше\n",
    "    df['days_since_last_interaction'] = (prediction_time_days - df['b_timestamp_max']).fillna(10000)\n",
    "\n",
    "    # --- Конец исправления для days_since_last_interaction ---\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_collaborative_features(df_candidates, train_hist_df, n_factors=10):\n",
    "    \"\"\"\n",
    "    Добавляет признаки на основе матричной факторизации (SVD).\n",
    "    Это более сложный признак, но часто эффективный.\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    \n",
    "    df = df_candidates.copy()\n",
    "    \n",
    "    # Создание разреженной матрицы user-item (например, на основе has_read)\n",
    "    interaction_matrix = train_hist_df.pivot(index='user_id', columns='book_id', values='has_read').fillna(0)\n",
    "    \n",
    "    # Применение SVD\n",
    "    svd = TruncatedSVD(n_components=n_factors, random_state=42)\n",
    "    user_factors = svd.fit_transform(interaction_matrix)\n",
    "    item_factors = svd.components_.T\n",
    "\n",
    "    # Создание словарей для быстрого доступа к векторам\n",
    "    user_factors_dict = {uid: vec for uid, vec in zip(interaction_matrix.index, user_factors)}\n",
    "    item_factors_dict = {bid: vec for bid, vec in zip(interaction_matrix.columns, item_factors)}\n",
    "\n",
    "    # Функция для получения признаков\n",
    "    def get_user_factor_features(user_id):\n",
    "        return user_factors_dict.get(user_id, np.zeros(n_factors))\n",
    "    \n",
    "    def get_book_factor_features(book_id):\n",
    "        return item_factors_dict.get(book_id, np.zeros(n_factors))\n",
    "\n",
    "    # Применение\n",
    "    user_factor_features = df['user_id'].apply(get_user_factor_features).apply(pd.Series)\n",
    "    user_factor_features.columns = [f'user_factor_{i}' for i in range(n_factors)]\n",
    "    \n",
    "    book_factor_features = df['book_id'].apply(get_book_factor_features).apply(pd.Series)\n",
    "    book_factor_features.columns = [f'book_factor_{i}' for i in range(n_factors)]\n",
    "\n",
    "    df = pd.concat([df, user_factor_features, book_factor_features], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_popularity_trend_features(df_candidates, train_hist_df):\n",
    "    \"\"\"\n",
    "    Добавляет признаки, связанные с популярностью книги в разные временные периоды.\n",
    "    \"\"\"\n",
    "    df = df_candidates.copy()\n",
    "    \n",
    "    # Добавим колонку года для агрегации\n",
    "    train_hist_with_year = train_hist_df.copy()\n",
    "    train_hist_with_year['year'] = train_hist_with_year['timestamp'].dt.year\n",
    "    \n",
    "    # Популярность книги в последнем году\n",
    "    last_year = train_hist_with_year['year'].max()\n",
    "    book_popularity_last_year = (\n",
    "        train_hist_with_year[train_hist_with_year['year'] == last_year]\n",
    "        .groupby('book_id')['user_id']\n",
    "        .nunique()\n",
    "        .rename('book_popularity_last_year')\n",
    "        .reset_index()\n",
    "    )\n",
    "    df = df.merge(book_popularity_last_year, on='book_id', how='left')\n",
    "    \n",
    "    # Заполняем NaN для книг, которые не были популярны в последнем году\n",
    "    df['book_popularity_last_year'] = df['book_popularity_last_year'].fillna(0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_genre_features(df_candidates, train_hist_df, books_metadata_df):\n",
    "    \"\"\"\n",
    "    Добавляет признак genre_match: есть ли у книги жанр, совпадающий с предпочтительным у пользователя.\n",
    "    \"\"\"\n",
    "    df = df_candidates.copy()\n",
    "\n",
    "    # Добавляем список жанров книги\n",
    "    df = df.merge(books_metadata_df[['book_id', 'genre_id']], on='book_id', how='left')\n",
    "\n",
    "    # Находим предпочтительный жанр пользователя (как раньше)\n",
    "    user_preferred_genres = (\n",
    "        train_hist_df\n",
    "        .merge(books_metadata_df[['book_id', 'genre_id']], on='book_id', how='left')\n",
    "        .explode('genre_id')  # раскрываем списки\n",
    "        .dropna(subset=['genre_id'])\n",
    "        .groupby(['user_id', 'genre_id'])['book_id']\n",
    "        .count()\n",
    "        .groupby('user_id')\n",
    "        .idxmax()\n",
    "        .apply(lambda x: x[1])\n",
    "        .rename('preferred_genre')\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    df = df.merge(user_preferred_genres, on='user_id', how='left')\n",
    "\n",
    "    # Функция: проверяет, есть ли preferred_genre в списке жанров книги\n",
    "    def has_preferred_genre(row):\n",
    "        preferred = row['preferred_genre']\n",
    "        genres = row['genre_id']\n",
    "        if pd.isna(preferred) or not isinstance(genres, list):\n",
    "            return 0\n",
    "        return int(preferred in genres)\n",
    "\n",
    "    df['genre_match'] = df.apply(has_preferred_genre, axis=1)\n",
    "\n",
    "    # Убираем служебные колонки\n",
    "    df = df.drop(columns=['genre_id', 'preferred_genre'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_author_features(df_candidates, train_hist_df, books_metadata_df):\n",
    "    \"\"\"\n",
    "    Добавляет признаки, связанные с авторами.\n",
    "    Требуется внешний датафрейм books_metadata_df с колонками ['book_id', 'author_id'].\n",
    "    \"\"\"\n",
    "    df = df_candidates.copy()\n",
    "    \n",
    "    # Пример: совпадает ли автор книги с \"предпочтительным\" автором пользователя\n",
    "    # Предполагаем, что в books_metadata_df есть колонка 'author_id'\n",
    "    df = df.merge(books_metadata_df[['book_id', 'author_id']], on='book_id', how='left')\n",
    "    \n",
    "    # Находим \"предпочтительного\" автора для каждого пользователя\n",
    "    user_preferred_authors = (\n",
    "        train_hist_df.merge(books_metadata_df[['book_id', 'author_id']], on='book_id', how='left')\n",
    "        .groupby(['user_id', 'author_id'])['book_id']\n",
    "        .count()\n",
    "        .groupby('user_id')\n",
    "        .idxmax()\n",
    "        .apply(lambda x: x[1]) # Получаем author_id\n",
    "        .rename('preferred_author')\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    df = df.merge(user_preferred_authors, on='user_id', how='left')\n",
    "    df['author_match'] = (df['author_id'] == df['preferred_author']).astype(int)\n",
    "    \n",
    "    # Заполняем NaN (например, если у пользователя не было взаимодействий или автор неизвестен)\n",
    "    df['author_match'] = df['author_match'].fillna(0)\n",
    "    df = df.drop(columns=['author_id','preferred_author'])\n",
    "    return df\n",
    "\n",
    "def add_all_new_features(df_candidates, train_hist_df, books_metadata_df=books_metadata_df, split_time=None):\n",
    "    \"\"\"\n",
    "    Применяет все вышеуказанные функции для добавления признаков.\n",
    "    split_time: datetime - время разбиения, передаётся в add_temporal_features.\n",
    "    \"\"\"\n",
    "    df = df_candidates.copy()\n",
    "    # Передаём split_time в add_temporal_features\n",
    "    df = add_interaction_features(df, train_hist_df)\n",
    "    df = add_temporal_features(df, train_hist_df, split_time=split_time)\n",
    "    df = add_collaborative_features(df, train_hist_df) # Закомментировано из-за сложности\n",
    "    df = add_popularity_trend_features(df, train_hist_df)\n",
    "    if books_metadata_df is not None:\n",
    "        df = add_genre_features(df, train_hist_df, books_metadata_df)\n",
    "        df = add_author_features(df, train_hist_df, books_metadata_df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b93db8a9-a190-4029-8bcc-f148fadb0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_history_and_popularity(df):\n",
    "    user_hist_books = (\n",
    "        df\n",
    "        .groupby('user_id')['book_id']\n",
    "        .agg(lambda x: set(x.tolist()))\n",
    "        .to_dict()\n",
    "    )\n",
    "    book_popularity = (\n",
    "        df\n",
    "        .groupby('book_id')['user_id']\n",
    "        .nunique()\n",
    "        .sort_values(ascending=False)\n",
    "    )\n",
    "    popular_books = book_popularity.index.to_numpy()\n",
    "    return user_hist_books, popular_books\n",
    "\n",
    "\n",
    "def sample_cold_candidates_for_user(user_id, user_hist_books, popular_books, n_cold=N_COLD):\n",
    "    seen = user_hist_books.get(user_id, set())\n",
    "    cold = []\n",
    "    for b in popular_books:\n",
    "        if b not in seen:\n",
    "            cold.append(b)\n",
    "            if len(cold) >= n_cold:\n",
    "                break\n",
    "    return cold\n",
    "\n",
    "\n",
    "def build_cold_candidates(users, user_hist_books, popular_books, n_cold=N_COLD):\n",
    "    rows = []\n",
    "    for u in users:\n",
    "        cold_books = sample_cold_candidates_for_user(u, user_hist_books, popular_books, n_cold=n_cold)\n",
    "        for b in cold_books:\n",
    "            rows.append((u, b, 0))\n",
    "    df = pd.DataFrame(rows, columns=['user_id', 'book_id', 'rel'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_basic_features(df_candidates, user_stats_df, book_stats_df, hist_df):\n",
    "    df = df_candidates.copy()\n",
    "    df = df.merge(user_stats_df, on='user_id', how='left')\n",
    "    df = df.merge(book_stats_df, on='book_id', how='left')\n",
    "    df = add_all_new_features(df, hist_df)\n",
    "    df = df.fillna(0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c60b885-0745-405b-9168-09f3861c0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_at_k(rels, k=20):\n",
    "    rels = np.asarray(rels)[:k]\n",
    "    if rels.size == 0:\n",
    "        return 0.0\n",
    "    return float(sum(rel / log2(i + 2) for i, rel in enumerate(rels)))\n",
    "\n",
    "\n",
    "def ndcg_for_user(df_u, k=20):\n",
    "    df_sorted = df_u.sort_values('pred', ascending=False)\n",
    "    rels_pred = df_sorted['rel'].values\n",
    "    dcg = dcg_at_k(rels_pred, k=k)\n",
    "    ideal_rels = np.sort(df_u['rel'].values)[::-1]\n",
    "    idcg = dcg_at_k(ideal_rels, k=k)\n",
    "    if idcg == 0:\n",
    "        return 0.0\n",
    "    return dcg / idcg\n",
    "\n",
    "\n",
    "def mean_ndcg(df, k=20):\n",
    "    scores = []\n",
    "    for user_id, df_u in df.groupby('user_id'):\n",
    "        score_u = ndcg_for_user(df_u, k=k)\n",
    "        scores.append(score_u)\n",
    "    if not scores:\n",
    "        return 0.0\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "def make_submission_user_list(df_pred, top_k=20):\n",
    "    submission_rows = []\n",
    "    for user_id, df_u in df_pred.groupby('user_id'):\n",
    "        df_sorted = df_u.sort_values('pred', ascending=False)\n",
    "        top_books = df_sorted['book_id'].head(top_k).tolist()\n",
    "        book_id_list_str = \",\".join(map(str, top_books))\n",
    "        submission_rows.append((user_id, book_id_list_str))\n",
    "    sub = pd.DataFrame(submission_rows, columns=['user_id', 'book_id_list'])\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ced047e2-3577-43b0-9d16-1f4ed96c2081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Позитивные/полупозитивные примеры в val_period: (53812, 3)\n",
      "        user_id  book_id  rel\n",
      "215249  1551451  2573361    2\n",
      "215250  1397150  2538344    2\n",
      "215251  1358090  2019613    2\n",
      "215252   849910  2366271    2\n",
      "215253   849910  1716389    1\n",
      "Количество холодных кандидатов: (60495, 3)\n",
      "   user_id  book_id  rel\n",
      "0  1551451   459282    0\n",
      "1  1551451  2287749    0\n",
      "2  1551451  2318816    0\n",
      "3  1551451  1796985    0\n",
      "4  1551451  1360858    0\n",
      "Итоговый размер val_candidates: (113171, 3)\n",
      "   user_id  book_id  rel\n",
      "0  1551451  2573361    2\n",
      "1  1397150  2538344    2\n",
      "2  1358090  2019613    2\n",
      "3   849910  2366271    2\n",
      "4   849910  1716389    1\n"
     ]
    }
   ],
   "source": [
    "val_period = val_period.copy()\n",
    "val_period['rel'] = np.where(val_period['has_read'] == 1, 2, 1)\n",
    "val_pos = val_period[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "print(\"Позитивные/полупозитивные примеры в val_period:\", val_pos.shape)\n",
    "print(val_pos.head())\n",
    "\n",
    "user_hist_books_hist, popular_books_hist = build_history_and_popularity(train_hist)\n",
    "val_users = val_period['user_id'].unique()\n",
    "val_cold = build_cold_candidates(val_users, user_hist_books_hist, popular_books_hist, n_cold=N_COLD)\n",
    "\n",
    "print(\"Количество холодных кандидатов:\", val_cold.shape)\n",
    "print(val_cold.head())\n",
    "\n",
    "val_candidates = pd.concat([val_pos, val_cold], ignore_index=True)\n",
    "val_candidates = val_candidates.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Итоговый размер val_candidates:\", val_candidates.shape)\n",
    "print(val_candidates.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a9971a5f-3c66-4141-9bad-362cceeaf11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train_candidates_hist: (305519, 3)\n",
      "Распределение rel в train_candidates_hist:\n",
      "rel\n",
      "0     90270\n",
      "1     89214\n",
      "2    126035\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_hist_full = train_hist.copy()\n",
    "train_hist_full['rel'] = np.where(train_hist_full['has_read'] == 1, 2, 1)\n",
    "train_hist_pos = train_hist_full[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "train_hist_users = train_hist_full['user_id'].unique()\n",
    "train_hist_cold = build_cold_candidates(train_hist_users, user_hist_books_hist, popular_books_hist, n_cold=N_COLD)\n",
    "\n",
    "train_candidates_hist = pd.concat([train_hist_pos, train_hist_cold], ignore_index=True)\n",
    "train_candidates_hist = train_candidates_hist.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Размер train_candidates_hist:\", train_candidates_hist.shape)\n",
    "print(\"Распределение rel в train_candidates_hist:\")\n",
    "print(train_candidates_hist['rel'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "894ea982-ccab-47de-aeac-1e898e29444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример агрегатов по книгам (hist):\n",
      "   book_id  n_interactions  n_read  n_plan  read_rate  plan_rate\n",
      "0       20             111      94      17   0.846847   0.153153\n",
      "1       35               1       1       0   0.999999   0.000000\n",
      "2       52               1       1       0   0.999999   0.000000\n",
      "3       54               5       4       1   0.800000   0.200000\n",
      "4       69               1       1       0   0.999999   0.000000\n",
      "Пример агрегатов по пользователям (hist):\n",
      "   user_id  u_n_interactions  u_n_read  u_n_plan  u_read_share\n",
      "0      151                75        36        39      0.480000\n",
      "1      210                31         0        31      0.000000\n",
      "2      560                 5         0         5      0.000000\n",
      "3     1380                46        19        27      0.413043\n",
      "4     1850                77        38        39      0.493506\n"
     ]
    }
   ],
   "source": [
    "book_stats_hist = (train_hist\n",
    "    .groupby('book_id')\n",
    "    .agg(\n",
    "        n_interactions=('user_id', 'nunique'),\n",
    "        n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "book_stats_hist['read_rate'] = book_stats_hist['n_read'] / (book_stats_hist['n_read'] + book_stats_hist['n_plan'] + 1e-6)\n",
    "book_stats_hist['plan_rate'] = book_stats_hist['n_plan'] / (book_stats_hist['n_read'] + book_stats_hist['n_plan'] + 1e-6)\n",
    "\n",
    "user_stats_hist = (train_hist\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        u_n_interactions=('book_id', 'nunique'),\n",
    "        u_n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        u_n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_stats_hist['u_read_share'] = user_stats_hist['u_n_read'] / (user_stats_hist['u_n_interactions'] + 1e-6)\n",
    "\n",
    "print(\"Пример агрегатов по книгам (hist):\")\n",
    "print(book_stats_hist.head())\n",
    "print(\"Пример агрегатов по пользователям (hist):\")\n",
    "print(user_stats_hist.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faabdbae-6b5b-44a3-bae0-ae765da8f0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков: 43\n",
      "Распределение rel в train_features_hist:\n",
      "rel\n",
      "0     90270\n",
      "1     89232\n",
      "2    126059\n",
      "Name: count, dtype: int64\n",
      "Распределение rel в val_features:\n",
      "rel\n",
      "0    59359\n",
      "1    23250\n",
      "2    30571\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_features_hist = add_basic_features(train_candidates_hist, user_stats_hist, book_stats_hist, train_hist)\n",
    "val_features = add_basic_features(val_candidates, user_stats_hist, book_stats_hist, val_period)\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in train_features_hist.columns\n",
    "    if c not in ['user_id', 'book_id', 'rel']\n",
    "]\n",
    "\n",
    "X_train = train_features_hist[feature_cols]\n",
    "y_train_rel = train_features_hist['rel']\n",
    "y_train_read = (train_features_hist['rel'] == 2).astype(int)\n",
    "y_train_any = (train_features_hist['rel'] > 0).astype(int)\n",
    "\n",
    "X_val = val_features[feature_cols]\n",
    "y_val_rel = val_features['rel']\n",
    "\n",
    "print(\"Число признаков:\", len(feature_cols))\n",
    "print(\"Распределение rel в train_features_hist:\")\n",
    "print(y_train_rel.value_counts().sort_index())\n",
    "print(\"Распределение rel в val_features:\")\n",
    "print(y_val_rel.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054804e0-229b-4c98-8784-9d36a8580201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример предсказаний (валидация):\n",
      "   user_id  book_id  rel      pred\n",
      "0  1551451  2573361    2  0.999408\n",
      "1  1397150  2538344    2  0.956788\n",
      "2  1358090  2019613    2  0.996862\n",
      "3   849910  2366271    2  0.721512\n",
      "4   849910  1716389    1  0.621960\n"
     ]
    }
   ],
   "source": [
    "xgb_read_cv = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_any_cv = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=43,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_read_cv.fit(X_train, y_train_read)\n",
    "xgb_any_cv.fit(X_train, y_train_any)\n",
    "\n",
    "cb_read_cv = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "cb_any_cv = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=43\n",
    ")\n",
    "\n",
    "cb_read_cv.fit(X_train, y_train_read)\n",
    "cb_any_cv.fit(X_train, y_train_any)\n",
    "\n",
    "p_read_xgb_val = xgb_read_cv.predict_proba(X_val)[:, 1]\n",
    "p_any_xgb_val = xgb_any_cv.predict_proba(X_val)[:, 1]\n",
    "score_xgb_val = w1 * p_read_xgb_val + w2 * p_any_xgb_val\n",
    "\n",
    "p_read_cb_val = cb_read_cv.predict_proba(X_val)[:, 1]\n",
    "p_any_cb_val = cb_any_cv.predict_proba(X_val)[:, 1]\n",
    "score_cb_val = w1 * p_read_cb_val + w2 * p_any_cb_val\n",
    "\n",
    "val_features['score_xgb'] = score_xgb_val\n",
    "val_features['score_cb'] = score_cb_val\n",
    "val_features['score_ens'] = (score_xgb_val + score_cb_val) / 2.0\n",
    "val_features['pred'] = val_features['score_ens']\n",
    "\n",
    "print(\"Пример предсказаний (валидация):\")\n",
    "print(val_features[['user_id', 'book_id', 'rel', 'pred']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2461021-65a4-4606-b252-85200c08cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@20 на валидации: 0.97377\n"
     ]
    }
   ],
   "source": [
    "ndcg20 = mean_ndcg(val_features, k=20)\n",
    "print(f\"NDCG@20 на валидации: {ndcg20:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a934433-c323-4f7a-a481-44f226dcebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train_candidates_full: (378396, 3)\n",
      "Распределение rel в train_candidates_full:\n",
      "rel\n",
      "0    109335\n",
      "1    112458\n",
      "2    156603\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_full = train.copy()\n",
    "train_full['rel'] = np.where(train_full['has_read'] == 1, 2, 1)\n",
    "train_pos_full = train_full[['user_id', 'book_id', 'rel']].drop_duplicates()\n",
    "\n",
    "user_hist_books_full, popular_books_full = build_history_and_popularity(train)\n",
    "train_users_full = train_full['user_id'].unique()\n",
    "train_cold_full = build_cold_candidates(train_users_full, user_hist_books_full, popular_books_full, n_cold=N_COLD)\n",
    "\n",
    "train_candidates_full = pd.concat([train_pos_full, train_cold_full], ignore_index=True)\n",
    "train_candidates_full = train_candidates_full.drop_duplicates(['user_id', 'book_id'])\n",
    "\n",
    "print(\"Размер train_candidates_full:\", train_candidates_full.shape)\n",
    "print(\"Распределение rel в train_candidates_full:\")\n",
    "print(train_candidates_full['rel'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f95d79d-93c0-4f97-8be2-39ff926c4b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример агрегатов по книгам (full):\n",
      "   book_id  n_interactions  n_read  n_plan  read_rate  plan_rate\n",
      "0       20             122     103      19   0.844262   0.155738\n",
      "1       35               1       1       0   0.999999   0.000000\n",
      "2       52               1       1       0   0.999999   0.000000\n",
      "3       54               7       5       2   0.714286   0.285714\n",
      "4       69               1       1       0   0.999999   0.000000\n",
      "Пример агрегатов по пользователям (full):\n",
      "   user_id  u_n_interactions  u_n_read  u_n_plan  u_read_share\n",
      "0      151                75        36        39      0.480000\n",
      "1      210                31         0        31      0.000000\n",
      "2      560                 6         0         6      0.000000\n",
      "3     1380                56        29        27      0.517857\n",
      "4     1850                77        38        39      0.493506\n"
     ]
    }
   ],
   "source": [
    "book_stats_full = (train\n",
    "    .groupby('book_id')\n",
    "    .agg(\n",
    "        n_interactions=('user_id', 'nunique'),\n",
    "        n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "book_stats_full['read_rate'] = book_stats_full['n_read'] / (book_stats_full['n_read'] + book_stats_full['n_plan'] + 1e-6)\n",
    "book_stats_full['plan_rate'] = book_stats_full['n_plan'] / (book_stats_full['n_read'] + book_stats_full['n_plan'] + 1e-6)\n",
    "\n",
    "user_stats_full = (train\n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        u_n_interactions=('book_id', 'nunique'),\n",
    "        u_n_read=('has_read', lambda x: int((x == 1).sum())),\n",
    "        u_n_plan=('has_read', lambda x: int((x == 0).sum()))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "user_stats_full['u_read_share'] = user_stats_full['u_n_read'] / (user_stats_full['u_n_interactions'] + 1e-6)\n",
    "\n",
    "print(\"Пример агрегатов по книгам (full):\")\n",
    "print(book_stats_full.head())\n",
    "print(\"Пример агрегатов по пользователям (full):\")\n",
    "print(user_stats_full.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5980108-1fe6-4d3d-a54b-6b15a0e020bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число признаков (full): 43\n",
      "Распределение rel (full):\n",
      "rel\n",
      "0    109335\n",
      "1    112482\n",
      "2    156630\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_features_full = add_basic_features(train_candidates_full, user_stats_full, book_stats_full, train)\n",
    "\n",
    "feature_cols_full = [\n",
    "    c for c in train_features_full.columns\n",
    "    if c not in ['user_id', 'book_id', 'rel']\n",
    "]\n",
    "\n",
    "X_full = train_features_full[feature_cols_full]\n",
    "y_full_rel = train_features_full['rel']\n",
    "y_full_read = (train_features_full['rel'] == 2).astype(int)\n",
    "y_full_any = (train_features_full['rel'] > 0).astype(int)\n",
    "\n",
    "print(\"Число признаков (full):\", len(feature_cols_full))\n",
    "print(\"Распределение rel (full):\")\n",
    "print(y_full_rel.value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "373c9537-1908-4724-841b-bf551e2b2832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальные модели (XGBoost + CatBoost) обучены на полном тренировочном датасете.\n"
     ]
    }
   ],
   "source": [
    "xgb_read_full = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=100,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_any_full = xgb.XGBClassifier(\n",
    "    n_estimators=800,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.025,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=101,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_read_full.fit(X_full, y_full_read)\n",
    "xgb_any_full.fit(X_full, y_full_any)\n",
    "\n",
    "cb_read_full = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=100\n",
    ")\n",
    "\n",
    "cb_any_full = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=8,\n",
    "    learning_rate=0.025,\n",
    "    loss_function='Logloss',\n",
    "    verbose=False,\n",
    "    random_seed=101\n",
    ")\n",
    "\n",
    "cb_read_full.fit(X_full, y_full_read)\n",
    "cb_any_full.fit(X_full, y_full_any)\n",
    "\n",
    "print(\"Финальные модели (XGBoost + CatBoost) обучены на полном тренировочном датасете.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e09f03bc-42e8-422b-b4fd-89480c12abff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер candidates_raw: (3512, 2)\n",
      "Колонки candidates_raw: ['user_id', 'book_id_list']\n",
      "   user_id                                       book_id_list\n",
      "0      210  11936,254097,709075,840500,971259,1037723,1074...\n",
      "1     1380  8369,28302,145975,482934,625734,998313,1098150...\n",
      "2     2050  4902,8369,18790,308364,317849,460492,822326,86...\n",
      "3     2740  39221,112023,149611,162418,181062,317050,43565...\n",
      "4     4621  28638,28639,28642,28901,31479,307058,475353,57...\n",
      "Длинный формат candidates_long: (81048, 2)\n",
      "   user_id  book_id\n",
      "0      210    11936\n",
      "0      210   254097\n",
      "0      210   709075\n",
      "0      210   840500\n",
      "0      210   971259\n"
     ]
    }
   ],
   "source": [
    "candidates_path = \"./data/raw/candidates.csv\"\n",
    "candidates_raw = pd.read_csv(candidates_path)\n",
    "\n",
    "print(\"Размер candidates_raw:\", candidates_raw.shape)\n",
    "print(\"Колонки candidates_raw:\", candidates_raw.columns.tolist())\n",
    "print(candidates_raw.head())\n",
    "\n",
    "candidates_long = candidates_raw.copy()\n",
    "candidates_long['book_id_list'] = candidates_long['book_id_list'].fillna('').astype(str)\n",
    "candidates_long['book_id_list'] = candidates_long['book_id_list'].str.split(',')\n",
    "candidates_long = candidates_long.explode('book_id_list')\n",
    "candidates_long = candidates_long[candidates_long['book_id_list'].str.strip() != '']\n",
    "candidates_long['book_id'] = candidates_long['book_id_list'].str.strip().astype(int)\n",
    "candidates_long = candidates_long[['user_id', 'book_id']].drop_duplicates()\n",
    "\n",
    "print(\"Длинный формат candidates_long:\", candidates_long.shape)\n",
    "print(candidates_long.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2c06457-1a57-40d3-b6bb-f36f733c8733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер test_features после join'ов: (81051, 45)\n",
      "   user_id  book_id  u_n_interactions  u_n_read  u_n_plan  u_read_share  \\\n",
      "0      210    11936                31         0        31           0.0   \n",
      "1      210   254097                31         0        31           0.0   \n",
      "2      210   709075                31         0        31           0.0   \n",
      "3      210   840500                31         0        31           0.0   \n",
      "4      210   971259                31         0        31           0.0   \n",
      "\n",
      "   n_interactions  n_read  n_plan  read_rate  ...  book_factor_3  \\\n",
      "0           396.0   375.0    21.0   0.946970  ...      -0.065552   \n",
      "1           360.0   325.0    35.0   0.902778  ...      -0.035147   \n",
      "2           198.0   130.0    68.0   0.656566  ...       0.020347   \n",
      "3            91.0    70.0    21.0   0.769231  ...       0.042907   \n",
      "4             1.0     0.0     1.0   0.000000  ...       0.000000   \n",
      "\n",
      "   book_factor_4  book_factor_5  book_factor_6  book_factor_7  book_factor_8  \\\n",
      "0       0.024550      -0.036846      -0.003760      -0.074338      -0.010901   \n",
      "1       0.037585      -0.033751       0.017214      -0.043550      -0.007050   \n",
      "2      -0.074870      -0.029536      -0.052742       0.012417      -0.012051   \n",
      "3      -0.024687       0.008972      -0.040379      -0.059328       0.045461   \n",
      "4       0.000000       0.000000       0.000000       0.000000       0.000000   \n",
      "\n",
      "   book_factor_9  book_popularity_last_year  genre_match  author_match  \n",
      "0      -0.007982                       52.0            0             0  \n",
      "1      -0.021551                       35.0            0             0  \n",
      "2      -0.015439                       26.0            0             0  \n",
      "3       0.113043                       60.0            0             0  \n",
      "4      -0.000000                        0.0            0             0  \n",
      "\n",
      "[5 rows x 45 columns]\n",
      "Пример предсказаний на candidates_long:\n",
      "   user_id  book_id      pred\n",
      "0      210    11936  0.203479\n",
      "1      210   254097  0.303504\n",
      "2      210   709075  0.301008\n",
      "3      210   840500  0.300801\n",
      "4      210   971259  0.300155\n"
     ]
    }
   ],
   "source": [
    "test_features = add_basic_features(candidates_long, user_stats_full, book_stats_full, train)\n",
    "\n",
    "print(\"Размер test_features после join'ов:\", test_features.shape)\n",
    "print(test_features.head())\n",
    "\n",
    "X_test = test_features[feature_cols_full]\n",
    "\n",
    "p_read_xgb_test = xgb_read_full.predict_proba(X_test)[:, 1]\n",
    "p_any_xgb_test = xgb_any_full.predict_proba(X_test)[:, 1]\n",
    "score_xgb_test = w1 * p_read_xgb_test + w2 * p_any_xgb_test\n",
    "\n",
    "p_read_cb_test = cb_read_full.predict_proba(X_test)[:, 1]\n",
    "p_any_cb_test = cb_any_full.predict_proba(X_test)[:, 1]\n",
    "score_cb_test = w1 * p_read_cb_test + w2 * p_any_cb_test\n",
    "\n",
    "test_features['score_xgb'] = score_xgb_test\n",
    "test_features['score_cb'] = score_cb_test\n",
    "test_features['pred'] = (score_xgb_test + score_cb_test) / 2.0\n",
    "\n",
    "print(\"Пример предсказаний на candidates_long:\")\n",
    "print(test_features[['user_id', 'book_id', 'pred']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83c1b0f2-3acb-4812-b783-c94b2bf47f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример сабмита (формат A):\n",
      "   user_id                                       book_id_list\n",
      "0      210  254097,2447113,3015694,2274394,1037723,2180196...\n",
      "1     1380  2290484,2548861,482934,8467358,8369,28302,2379...\n",
      "2     2050  18790,2254200,1918727,2575827,867246,8369,1240...\n",
      "3     2740  987516,5535190,2327258,1834192,549194,2479424,...\n",
      "4     4621  2595660,1964216,2446687,2347564,2347566,134176...\n",
      "Сабмит сохранён в: ./output/submissions/submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_features = test_features.drop_duplicates(subset=['user_id', 'book_id']).reset_index(drop=True)\n",
    "\n",
    "submission_user_list = make_submission_user_list(test_features, top_k=20)\n",
    "\n",
    "print(\"Пример сабмита (формат A):\")\n",
    "print(submission_user_list.head())\n",
    "\n",
    "submit_path = \"./output/submissions/submission.csv\"\n",
    "submission_user_list.to_csv(submit_path, index=False)\n",
    "print(\"Сабмит сохранён в:\", submit_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804a060-1092-4b95-8e36-93c3a8a92568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
